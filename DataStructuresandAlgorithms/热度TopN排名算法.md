# 热度TopN排名算法

## 1. 概述

**我们用不同方法，企图解决的都是同一个问题：根据用户的投票，决定最近一段时间内的"热文排名"。**

大致有如下这些算法：

* 0）[Delicious](http://www.ruanyifeng.com/blog/2012/02/ranking_algorithm_hacker_news.html)
* 1）[Hacker News](http://www.ruanyifeng.com/blog/2012/02/ranking_algorithm_hacker_news.html)
* 2）[Reddit](http://www.ruanyifeng.com/blog/2012/03/ranking_algorithm_reddit.html)
* 3）[Stack Overflow](http://www.ruanyifeng.com/blog/2012/03/ranking_algorithm_stack_overflow.html)
* 4）[牛顿冷却定律](http://www.ruanyifeng.com/blog/2012/03/ranking_algorithm_newton_s_law_of_cooling.html)
* 5）[威尔逊区间](http://www.ruanyifeng.com/blog/2012/03/ranking_algorithm_wilson_score_interval.html)
* 6）[贝叶斯平均](http://www.ruanyifeng.com/blog/2012/03/ranking_algorithm_bayesian_average.html)





## 2.详细

### 0. Delicious

最直觉、最简单的算法，莫过于按照单位时间内用户的投票数进行排名。得票最多的项目，自然就排在第一位。

> 旧版的[Delicious](http://www.google.com/url?sa=D&q=http://del.icio.us/&usg=AFQjCNFp5KllThyYtlA74rqSRKdqRtAjxw)，有一个"热门书签排行榜"，就是这样统计出来的。

它按照**"过去60分钟内被收藏的次数"**进行排名。每过60分钟，就统计一次。

这个算法的优点是比较简单、容易部署、内容更新相当快；缺点是，一方面，排名变化不够平滑，前一个小时还排名靠前的内容，往往第二个小时就一落千丈，另一方面，缺乏自动淘汰旧项目的机制，某些热门内容可能会长期占据排行榜前列。



### 1. Hacker News

> [Hacker News](http://news.ycombinator.com/)是一个网络社区，可以张贴链接，或者讨论某个主题。

公式如下：
$$
Score=\frac{(P+1)}{(T+2)^G}
$$

> 数学公式语法 https://www.jianshu.com/p/e74eb43960a1



* Score 最终得分
* P 即获赞数、投票数、点击数等等
  * 如果你不想让"高票帖子"与"低票帖子"的差距过大，可以在得票数上加一个小于1的指数，比如`(P-1)^0.8`。
* T 发布到现在过去的时间（小时）用于使得热度随着时间进行衰减
  * 之所以选择2，可能是因为从原始文章出现在其他网站，到转贴至Hacker News，平均需要两个小时
* G 重力因子 控制热度随时间衰减的速度（推荐值1.8）
  * G值越大，曲线越陡峭，排名下降得越快，意味着排行榜的更新速度越快。

> 

### 2. Reddit

> [Reddit](http://www.reddit.com/)是美国最大的网上社区，它的每个帖子前面都有向上和向下的箭头，分别表示"赞成"和"反对"。用户点击进行投票，Reddit根据投票结果，计算出最新的"热点文章排行榜"。

Reddit 会根据赞成数和反对数一起计算出TopN。

公式如下：
$$
Score=\log(z)+\frac{yt}{45000}
$$

* t 时间戳，帖子越新t则越大
* y 投票方向
  * 如果赞成票居多，y就是+1；
  * 如果反对票居多，y就是-1；
  * 如果赞成票和反对票相等，y就是0
* z  表示赞成票与反对票之间差额的绝对值
  * 如果对某个帖子的评价，越是一边倒，z就越大。如果赞成票等于反对票，z就等于1。

解析

> log(z) 赞成票与反对票的差额z越大，得分越高
>
> yt/45000 这个部分表示，t越大，得分越高，即新帖子的得分会高于老帖子。它起到自动将老帖子的排名往下拉的作用。
>
> y的作用是产生加分或减分。当赞成票超过反对票时，这一部分为正，起到加分作用；当赞成票少于反对票时，这一部分为负，起到减分作用；当两者相等，这一部分为0。这就保证了得到大量净赞成票的文章，会排在前列；赞成票与反对票接近或相等的文章，会排在后面；得到净反对票的文章，会排在最后（因为得分是负值）。

这种算法的一个问题是，对于那些有争议的文章（赞成票和反对票非常接近），它们不可能排到前列。假定同一时间有两个帖子发表，文章A有1张赞成票（发帖人投的）、0张反对票，文章B有1000张赞成票、1000张反对票，那么A的排名会高于B，这显然不合理。



**结论就是，Reddit的排名，基本上由发帖时间决定，超级受欢迎的文章会排在最前面，一般性受欢迎的文章、有争议的文章都不会很靠前。**



### 3. Stack Overflow

在Stack Overflow的页面上，每个问题前面有三个数字，分别表示`问题的得分`、`回答的数目`和`该问题的浏览次数`。以这些变量为基础，就可以设计算法了。

> 找出某段时间内的热点问题，即哪些问题最被关注、得到了最多的讨论



公式如下：
$$
\frac{logQviews*4+\frac{Qanswers*Qscores}{5}+sum(Ascores)}{(\frac{Qage}{2}+\frac{Qupdated}{2}+1)^G}
$$


* Qviews（问题的浏览次数）

  * 某个问题的浏览次数越多，就代表越受关注，得分也就越高。这里使用了以10为底的对数，用意是当访问量越来越大，它对得分的影响将不断变小。
  
* Qscore（问题得分）和Qanswers（回答的数量）

* Qscore（问题得分）= 赞成票-反对票。如果某个问题越受到好评，排名自然应该越靠前。
  
  * Qanswers表示回答的数量，代表有多少人参与这个问题。这个值越大，得分将成倍放大。这里需要注意的是，如果无人回答，Qanswers就等于0，这时Qscore再高也没用，意味着再好的问题，也必须有人回答，否则进不了热点问题排行榜。
  
* Ascores（回答得分）
  
  
  * 一般来说，"回答"比"问题"更有意义。这一项的得分越高，就代表回答的质量越高。
  * 首先，一个正确的回答胜过一百个无用的回答，但是，简单加总会导致，1个得分为100的回答与100个得分为1的回答，总得分相同。其次，由于得分会出现负值，因此那些特别差的回答，会拉低正确回答的得分。
  
* Qage（距离问题发表的时间）和Qupdated（距离最后一个回答的时间）

  * 	Qage和Qupdated的单位都是秒。如果一个问题的存在时间越久，或者距离上一次回答的时间越久，Qage和Qupdated的值就相应增大。
  * 	也就是说，随着时间流逝，这两个值都会越变越大，导致分母增大，因此总得分会越来越小。
  
* G 得分随时间衰减的速度 推荐是1.5

  

  Stack Overflow热点问题的排名，与**参与度**（Qviews和Qanswers）和**质量**（Qscore和Ascores）成正比，与**时间**（Qage和Qupdated）成反比。

  

  
### 4. 牛顿冷却定律


  我们可以把"热文排名"想象成一个"自然冷却"的过程：

* 1）任一时刻，网站中所有的文章，都有一个"当前温度"，温度最高的文章就排在第一位。
* 2）如果一个用户对某篇文章投了赞成票，该文章的温度就上升一度。
* 3）随着时间流逝，所有文章的温度都逐渐"冷却"。



然后直接套用牛顿冷却定律即可。

最终公式如下：
$$
T=T_0*e^{-α*(t-t0)}
$$


* T 本次冷却后的温度
* T0 t0时间的温度
* e 常数 其值约为2.71828
* α 冷却系数，负号表示降温
* t-t0 为时间差（小时），间隔越久降温越多



其中，"冷却系数"是一个你自己决定的值。如果假定一篇新文章的初始分数是100分，24小时之后"冷却"为1分，那么可以计算得到"冷却系数"约等于0.192。如果你想放慢"热文排名"的更新率，"冷却系数"就取一个较小的值，否则就取一个较大的值。

### 5.威尔逊区间

迄今为止，这个系列都在讨论，如何给出**"某个时段"**的排名，比如"过去24小时最热门的文章"。

但是，很多场合需要的是**"所有时段"**的排名，比如"最受用户好评的产品"。

这个时候时间因素就不用考虑了







### 6. 贝叶斯平均

> ["贝叶斯平均"](http://en.wikipedia.org/wiki/Bayesian_average)（Bayesian average）在某种程度上，它借鉴了["贝叶斯推断"](http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_one.html)（Bayesian inference）的思想：既然不知道投票结果，那就先估计一个值，然后不断用新的信息修正，使得它越来越接近正确的值。

以[IMDB](http://www.imdb.com/)为例，它是世界最大的电影数据库，观众可以对每部电影投票，最低为1分，最高为10分。

公式如下：
$$
Score=\frac{v}{v+m}R+\frac{v}{v+m}C
$$


* Score 加权得分
* v 投票人数
* m 排名前N名的最低投票数（可以是固定值）
* R 该电影的用户投票的平均得分
* C 所有电影的平均得分

仔细研究这个公式，你会发现，IMDB为每部电影增加了3000张选票，并且这些选票的评分都为6.9。这样做的原因是，假设所有电影都至少有3000张选票，那么就都具备了进入前250名的评选条件；然后假设这3000张选票的评分是所有电影的平均得分（即假设这部电影具有平均水准）；最后，用现有的观众投票进行修正，长期来看，v/(v+m)这部分的权重将越来越大，得分将慢慢接近真实情况。

这样做拉近了不同电影之间投票人数的差异，使得投票人数较少的电影也有可能排名前列。