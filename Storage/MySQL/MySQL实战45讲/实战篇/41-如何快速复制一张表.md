# 怎么最快地复制一张表？

## 1. 问题

如果可以控制对源表的扫描行数和加锁范围很小的话，我们简单地使用 insert … select 语句即可实现。

当然，为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表。这时，有两种常用的方法。

为了便于说明，我还是先创建一个表 db1.t，并插入 1000 行数据，同时创建一个相同结构的表 db2.t。

```mysql
create database db1;
use db1;

create table t(
    id int primary key, 
    a int, 
    b int, 
    index(a))engine=innodb;
delimiter ;;
  create procedure idata()
  begin
    declare i int;
    set i=1;
    while(i<=1000)do
      insert into t values(i,i,i);
      set i=i+1;
    end while;
  end;;
delimiter ;
call idata();

create database db2;
create table db2.t like db1.t
```

假设，我们要把 db1.t 里面 a>900 的数据行导出来，插入到 db2.t 中。



## 2. mysqldump 方法

用 mysqldump 命令将数据导出成一组 INSERT 语句。你可以使用下面的命令把结果输出到临时文件：

```sh
mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql
```

这条命令中，主要参数含义如下：

* –single-transaction 的作用是，在导出数据的时候不需要对表 db1.t 加表锁，而是使用 START TRANSACTION WITH CONSISTENT SNAPSHOT 的方法；
* –add-locks 设置为 0，表示在输出的文件结果里，不增加" LOCK TABLES t WRITE;" ；
* –no-create-info 的意思是，不需要导出表结构；
* –set-gtid-purged=off 表示的是，不输出跟 GTID 相关的信息；
* –result-file 指定了输出文件的路径，其中 client 表示生成的文件是在客户端机器上的。

通过这条 mysqldump 命令生成的 t.sql 文件中就包含一条 INSERT 语句

```mysql
insert into `t` values (901,901,901),(902,902,902)...(999)
```

一条 INSERT 语句里面会包含多个 value 对，这是为了后续用这个文件来写入数据的时候，执行速度可以更快。

> 如果你希望生成的文件中一条 INSERT 语句只插入一行数据的话，可以在执行 mysqldump 命令时，加上参数–skip-extended-insert。

然后，你可以通过下面这条命令，将这些 INSERT 语句放到 db2 库里去执行。

```mysql
mysql -h127.0.0.1 -P13000  -uroot db2 -e "source /client_tmp/t.sql"
```

**source 并不是一条 SQL 语句，而是一个客户端命令**。mysql 客户端执行这个命令的流程是这样的：

* 1）打开文件，默认以分号为结尾读取一条条的 SQL 语句；
* 2）将 SQL 语句发送到服务端执行。

也就是说，服务端执行的并不是这个`source /client_tmp/t.sql`语句，而是 t.sql 中的那个 INSERT 语句。



## 3. 导出 CSV 文件

### select into outfile

另一种方法是直接将结果导出成.csv 文件。MySQL 提供了下面的语法，用来将查询结果导出到服务端本地目录：

```mysql
select * from db1.t where a>900 into outfile '/server_tmp/t.csv';
```

注意事项：

* 1）**这条语句会将结果保存在服务端**。如果你执行命令的客户端和 MySQL 服务端不在同一个机器上，客户端机器的临时目录下是不会生成 t.csv 文件的。
* 2）**into outfile 指定了文件的生成位置（/server_tmp/），这个位置必须受参数 secure_file_priv 的限制**。参数 secure_file_priv 的可选值和作用分别是：
  * 如果设置为 empty，表示不限制文件生成的位置，这是不安全的设置；
  * 如果设置为一个表示路径的字符串，就要求生成的文件只能放在这个指定的目录，或者它的子目录；
  * 如果设置为 NULL，就表示禁止在这个 MySQL 实例上执行 select … into outfile 操作。
* 3）**这条命令不会帮你覆盖文件**，因此你需要确保 /server_tmp/t.csv 这个文件不存在，否则执行语句时就会因为有同名文件的存在而报错。
* 4）这条命令生成的文本文件中，原则上一个数据行对应文本文件的一行。但是，**如果字段中包含换行符，在生成的文本中也会有换行符**。不过类似换行符、制表符这类符号，前面都会跟上“\”这个转义符，这样就可以跟字段之间、数据行之间的分隔符区分开。

得到.csv 导出文件后，你就可以用下面的 load data 命令将数据导入到目标表 db2.t 中。

```mysql
load data infile '/server_tmp/t.csv' into table db2.t;
```

这条语句的执行流程如下所示。

* 1）打开文件 /server_tmp/t.csv，以制表符 (\t) 作为字段间的分隔符，以换行符（\n）作为记录之间的分隔符，进行数据读取；
* 2）启动事务。
* 3）判断每一行的字段数与表 db2.t 是否相同：
  * 若不相同，则直接报错，事务回滚；可以看做是一种 fast fail。
  * 若相同，则构造成一行，调用 InnoDB 引擎接口，写入到表中。
* 4）重复步骤 3，直到 /server_tmp/t.csv 整个文件读入完成，提交事务。



### 主备同步

**如果 binlog_format=statement，这个 load 语句记录到 binlog 里以后，怎么在备库重放呢？**

由于备库上没有这个文件，如果 binlog 中直接记录该文件，等同步到备库执行时肯定会失败。

所以，这条语句执行的完整流程，其实是下面这样的。

* 1）主库执行完成后，将 /server_tmp/t.csv 文件的内容直接写到 binlog 文件中。
* 2）往 binlog 文件中写入语句 `load data local infile ‘/tmp/SQL_LOAD_MB-1-0’ INTO TABLE db2.t`。
* 3）把这个 binlog 日志传到备库。
* 4）备库的 apply 线程在执行这个事务日志时：
  * a. 先将 binlog 中 t.csv 文件的内容读出来，写入到本地临时目录 /tmp/SQL_LOAD_MB-1-0 中；
  * b. 再执行 load data 语句，往备库的 db2.t 表中插入跟主库相同的数据。

注意，这里备库执行的 load data 语句里面，多了一个“local”。它的意思是“将执行这条命令的客户端所在机器的本地文件 /tmp/SQL_LOAD_MB-1-0 的内容，加载到目标表 db2.t 中”。

**load data 命令有两种用法**

* 1）**不加“local”，是读取服务端的文件**，这个文件必须在 secure_file_priv 指定的目录或子目录下；
* 2）**加上“local”，读取的是客户端的文件**，只要 mysql 客户端有访问这个文件的权限即可。这时候，MySQL 客户端会先把本地文件传给服务端，然后执行上述的 load data 流程。



### 表结构 

**select …into outfile 方法不会生成表结构文件**, 所以我们导数据时还需要单独的命令得到表结构定义。mysqldump 提供了一个–tab 参数，可以同时导出表结构定义文件和 csv 数据文件。这条命令的使用方法如下：

```mysql
mysqldump -h$host -P$port -u$user ---single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --tab=$secure_file_priv
```

这条命令会在 $secure_file_priv 定义的目录下，创建一个 t.sql 文件保存建表语句，同时创建一个 t.txt 文件保存 CSV 数据。



## 4. 物理拷贝方法

*直接把 db1.t 表的.frm 文件和.ibd 文件拷贝到 db2 目录下，是否可行呢？*

答案是不行的。

因为，一个 InnoDB 表，除了包含这两个物理文件外，还需要在数据字典中注册。直接拷贝这两个文件的话，因为数据字典中没有 db2.t 这个表，系统是不会识别和接受它们的。

不过，在 MySQL 5.6 版本引入了**可传输表空间(transportable tablespace)** 的方法，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。

假设我们现在的目标是在 db1 库下，复制一个跟表 t 相同的表 r，具体的执行步骤如下：

* 1）执行 create table r like t，创建一个相同表结构的空表；
* 2）执行 alter table r discard tablespace，这时候 r.ibd 文件会被删除；
* 3）执行 flush table t for export，这时候 db1 目录下会生成一个 t.cfg 文件；
* 4）在 db1 目录下使用cp命令复制出r.cfg、r.idb 这两个文件。 `cp t.cfg r.cfg; cp t.ibd r.ibd`；这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；
* 5）执行 unlock tables，这时候 t.cfg 文件会被删除；
* 6）执行 alter table r import tablespace，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。

> 核心就是通过 cp命令复制出r.cfg、r.idb 这两个文件。
>
> .cfg文件包含导入表空间文件时用于schema验证的元数据。
>
> .idb 则是表数据



关于拷贝表的这个流程，有以下几个注意点：

* 1）在第 3 步执行完 flsuh table 命令之后，db1.t 整个表处于只读状态，直到执行 unlock tables 命令后才释放读锁；
* 2）在执行 import tablespace 的时候，为了让文件里的表空间 id 和数据字典中的一致，会修改 r.ibd 的表空间 id。而这个表空间 id 存在于每一个数据页中。因此，如果是一个很大的文件（比如 TB 级别），每个数据页都需要修改，所以你会看到这个 import 语句的执行是需要一些时间的。当然，如果是相比于逻辑导入的方法，import 语句的耗时是非常短的。



## 5. 小结

* 1）物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：
  * 必须是全表拷贝，不能只拷贝部分数据；
  * 需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；
  * 由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。

* 2）用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 join 这种比较复杂的 where 条件写法。

* 3）用 select … into outfile 的方法是最灵活的，支持所有的 SQL 写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。