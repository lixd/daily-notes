# Nginx 缓存

## 1. 概述

**客户端缓存**

优点：直接在本地获取，没有网络消耗，响应最快

缺点：仅对单一用户生效

**服务端缓存**

优点：对所有用户生效；有效降低上游应用服务器压力

缺点：用户仍有网络消耗

**最佳实践**：同时启用客户端缓存和服务端缓存。



## 2. 缓存相关指令

### proxy_cache

是否开启缓存，默认关闭，指定zone 时就算开启。

语法：proxy_cache zone|off;

默认值：proxy_cache off;

上下文：http、server、location

### proxy_cache_path

定义缓存存放的位置。

语法：proxy_cache_path path keys_zone=name:size [大量可选参数];

默认值：proxy_cache_path off;

上下文：http

可选参数含义

path：缓存文件的存放路径

level：path的目录层级

user_temp_path：off时直接使用path路径，on时则使用proxy_temp_path路径。

keys_zone：name是共享内存名称，size是共享内存大小。

inactive：在指定时间内没有被访问的缓存会被清理掉，默认10分钟。

max_size：设定最大的缓存文件大小，超过后将由CacheManager清理。

manager_files：CacheManager清理一次缓存文件，最大清理的文件数，默认100

manager_sleep：CacheManager清理的时间间隔，默认200ms

manager_threshold:CM清理一次最长耗时，默认50ms

loader_files：CacheLoader 载入文件到共享内存，每批最多文件数，默认100

loader_sleep：CL 载入文件的间隔时间，默认200ms

loader_threshold：CL每次载入文件到共享内存的最大耗时，默认50ms



### proxy_cache_key

缓存key信息。

语法：proxy_cache_key string;

默认值：proxy_cache_key $scheme$proxy_host$request_uri

上下文：http、server、location





### proxy_cache_valid

设置只对哪些请求进行缓存。

语法：proxy_cache_valid [code...] time;

默认值：无

上下文：http、server、location

示例：proxy_cache_valid 60m; 不填httpcode时，默认只对200、301、302响应码进行缓存



### upstream_cache_status变量

该变量主要用于查看缓存是否命中。

相关状态列表：

* MISS：未命中
* HIT：命中缓存
* EXPIRED：缓存过期
* STALE：命中了陈旧缓存
* REVALIDDATED：Nginx 验证陈旧缓存依旧有效
* UPDATING：内容陈旧，但正在更新
* BYPASS：响应从原始服务器获取



## 3. 设置不缓存

### proxy_no_cache

设置某些请求不缓存。

语法：proxy_no_cache string；

默认值：无

上下文：http、server、location



### proxy_cache_bypass

语法：proxy_cache_bypass string；

默认值：无

上下文：http、server、location





## 4. 缓存失效--合并请求



### proxy_cache_lock

语法：proxy_cache_lock on|off;

默认值：proxy_cache_lock off；

上下文：http、server、location

开启后，假设同时有多个请求请求同一个文件，Nginx会对请求进行合并，只会放行一个请求到上游服务器，等该请求拿到数据后，其他请求直接从Nginx缓存中获取。

如果关闭则所有请求都会发送到上游服务器。

建议开启，以减轻上游服务器压力。



### proxy_cache_lock_timeout

语法：proxy_cache_lock_timeout time;

默认值：proxy_cache_lock_timeout 5s;

上下文：http、server、location

设置合并请求的超时时间，如果时间到了该请求还没返回，那么剩下的请求将会直接发送给上游服务器，不在继续等待了。



### proxy_cache_lock_age 

语法：proxy_cache_lock_age  time;

默认值：proxy_cache_lock_age 5s;

上下文：http、server、location

如果超时后，Nginx将剩余等待的请求全部发给上游服务器，势必会给上游服务器造成很大压力，配置 proxy_cache_lock_age 后，在超时后就只会在放行一个请求到上游服务器，如果又超时了，就再放行一个。



## 5. 缓存失效--启用旧缓存

在及时性要求不高的情况下，返回给用户一个陈旧的缓存也比直接报错要好。

或者是Nginx缓存过期了，为了不给上游服务器增加压力，也直接返回陈旧缓存。

> 注：第一个发现缓存过期的请求会被转发到上游服务器去拿最新的数据。在这个请求返回前，如果又来了其他请求，这个时候才会直接返回陈旧缓存给客户端。

如果发现缓存正在更新，也会直接拿陈旧缓存返回给客户端。



### proxy_cache_user_stale

指定什么请求下会返回陈旧缓存。

语法：proxy_cache_user_stale error|timeout|invalid_header|updating|http_500|http_502|http_503|http_504|http_403|http_404|http_429|off ...;

默认值：proxy_cache_user_stale off；

上下文：http、server、location



### proxy_cache_backgroud_update

语法：proxy_cache_backgroud_update on|off;

默认值：proxy_cache_backgroud_update off；

上下文：http、server、location

开启后，第一个请求过来，发现缓存过期了，也不会到上游服务器了，直接返回陈旧请求，然后Nginx后台会发起一个请求到上游服务器去拿最新的数据并更新缓存。





## 6. 第三方缓存清除模块 ngx_cache_purge

商业版Nginx自带了缓存清除功能，不过开源版本中没有，社区提供了第三方的模块供使用。

功能：根据接收的HTTP请求立即清除缓存

使用`--add-module`指定添加到 nginx 中。





### proxy_cache_purge

语法：proxy_cache_purge zone_name key；

默认值：无

上下文：http、server、location

设置缓存的时候也需要指定一个 key，Nginx 根据该key进行hash生成缓存key。

这里清除缓存也需要指定一个key，用于指定清除哪些数据。



### 基本使用

简单配置

```conf
location /cache_purge{
    proxy_cache_purge cache_zone index.html;
}
```

该配置实现了：访问 /cache_purge URI 时即可清理 index.html 文件的缓存。

不过这样一个文件一个文件配置太麻烦了，下面演示一种比较通用的配置：

该配置实现了，访问特定URL时即可清理对应缓存。

```conf
location / {
 proxy_cache_key $host$uri;
}

location ~ /cache_purge(/.*){
    proxy_cache_purge cache_zone $host$1;
}
```

第一个配置，配置缓存时用的 key 是 $host$uri，即host+uri作为缓存key。

第二个配置，清理缓存时每次都清理host+$1 这个参数组合对应的 key。而这里的 $1 对应的就是 /cache_purge 后拼接的URI。

即：访问 /cache_purge/index.html 时 $1 的值就是 /index.html

也就是会清理掉 /index.html 的缓存。

最终实现的效果就是/cache_purge后加什么URI就可以清理掉那个URI的缓存，使用起来比较方便。





proxy_cache_key $host$uri 和 proxy_cache_purge cache_zone $host$1 中的 key 是刚好对应的。

访问 xxx.com/cache_purge/123.html 时就会去清理 123.html 的缓存。



## 7. https

https 其实只是身披 TLS/SSL 协议外壳的 http。

http 的问题：

* 数据使用明文传输,可能被黑客窃取
* 报文的完整性无法验证,可能被黑客篡改
* 无法验证通信双方的身份,可能被黑客伪装



https 是如何解决 http 的问题的：

* 数据使用明文传输,可能被黑客窃取---信息加密
* 报文的完整性无法验证,可能被黑客篡改---完整性校验
* 无法验证通信双方的身份,可能被黑客伪装---身份认证



### 加密算法



* 对称加密,常见算法: DES、AES、3DES .
  * 优势：解密效率高
  * 劣势：
    * 密钥无法实现安全传输
    * 密钥难以管理
    * 无法提供信息完整性校验
* 非对称加密，常见算法: RSA、DSA、ECC
  * 优势：服务器只需维护一个私钥即可
  * 劣势：
    * 公钥是公开的
    * 加解密效率低
    * 公钥不包含服务器信息，存在中间人攻击的可能性



### https 加密原理

https混合使用对称加密和非对称加密：

* 连接建立阶段，使用非对称加密算法
* 内容传输阶段，使用对称加密算法



简单流程如下：

首先服务端有一对公私钥。

* 1）服务端将公钥发给客户端
* 2）客户端生成一个随机密钥(随机数)
* 3）将2中的随机数，用公钥加密后发给服务端
* 4）服务端利用私钥解密，得到随机数
* 5）二者后续传输内容都使用随机数进行对称加密

由于随机数是在客户端生成的，而且发生给服务端的时候用公钥加密了，只有私钥才能解密，这样就保证了这个随机数密钥不会被其他人知道。



### 完整性校验

* 1）服务端将消息内容进行 hash 运算，得到**消息摘要**
* 2）使用私钥对消息摘要进行加密，得到**数字签名**
* 3）最终将消息内容和数字签名都发生给客户端
* 4）客户端使用公钥解密数字签名得到消息摘要
* 5）客户端对消息内容进行 hash 运算，得到消息摘要
* 6）客户端对比两个消息摘要，即可确定消息是否被篡改

这样就解决了内容被篡改的问题，不过其实还有一个很大的问题：





### CA与中间人攻击

客户端如何校验收到的公钥就是服务端的呢？

比如在建立连接的时候就被黑客拦截了，最终形成了如下局面：

```conf
客户端 <---> 黑客 <---> 服务端
```

这样，包括公钥和数字签名，都是黑客发给客户端的，所以自然能够解密，也能通过校验，但是实际上内容还是被篡改了。

这就是**中间人攻击**。

为了校验服务端的公钥，于是需要一个 可信的第三方机构，CA。

> 至于为什么 CA 就是可信的呢？因为有公信度，就像我们可以放心的把钱存到银行，而不担心丢失的问题一样。

服务端的公钥是由 CA 机构颁发的，所以客户端拿到公钥后可以去 CA 校验，这个公钥是不是属于服务端的。

这样就避免了中间人攻击。
